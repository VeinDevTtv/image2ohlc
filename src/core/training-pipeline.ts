import { promises as fs } from 'fs';
import { join } from 'path';
import { DatasetGenerator, DatasetConfig, SegmentationClass } from './dataset-generator';

/**
 * Training configuration for the segmentation model
 */
export interface TrainingConfig {
  modelArchitecture: 'unet' | 'deeplab' | 'fcn';
  inputSize: {
    width: number;
    height: number;
  };
  batchSize: number;
  epochs: number;
  learningRate: number;
  optimizer: 'adam' | 'sgd' | 'rmsprop';
  lossFunction: 'categorical_crossentropy' | 'sparse_categorical_crossentropy' | 'dice_loss';
  metrics: string[];
  validationSplit: number;
  earlyStopping: {
    patience: number;
    monitor: string;
  };
  dataAugmentation: {
    horizontalFlip: boolean;
    verticalFlip: boolean;
    rotationRange: number;
    zoomRange: number;
    brightnessRange: number;
    contrastRange: number;
  };
}

/**
 * Model training results
 */
export interface TrainingResults {
  modelPath: string;
  trainingHistory: {
    loss: number[];
    accuracy: number[];
    valLoss: number[];
    valAccuracy: number[];
  };
  metrics: {
    finalAccuracy: number;
    finalLoss: number;
    valAccuracy: number;
    valLoss: number;
  };
  trainingTime: number;
  epochsTrained: number;
}

/**
 * Python training script generator for TensorFlow/Keras
 */
export class TrainingPipeline {
  private config: TrainingConfig;
  private datasetConfig: DatasetConfig;

  constructor(config: TrainingConfig, datasetConfig: DatasetConfig) {
    this.config = config;
    this.datasetConfig = datasetConfig;
  }

  /**
   * Generates Python training script
   */
  async generateTrainingScript(): Promise<string> {
    const script = `#!/usr/bin/env python3
"""
Candlestick Chart Segmentation Model Training Script
Generated by TypeScript Dataset Generator
"""

import os
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy
from tensorflow.keras.metrics import Accuracy, MeanIoU
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import argparse
from pathlib import Path

# Configuration
CONFIG = ${JSON.stringify(this.config, null, 2)}
DATASET_CONFIG = ${JSON.stringify(this.datasetConfig, null, 2)}

class CandlestickDatasetGenerator:
    """Custom dataset generator for candlestick segmentation"""
    
    def __init__(self, dataset_dir, batch_size=8, input_size=(512, 512)):
        self.dataset_dir = dataset_dir
        self.batch_size = batch_size
        self.input_size = input_size
        self.num_classes = len(DATASET_CONFIG['augmentationParams'])
        
    def load_dataset(self, split='train'):
        """Load images and masks for a specific split"""
        images_dir = os.path.join(self.dataset_dir, split, 'images')
        masks_dir = os.path.join(self.dataset_dir, split, 'masks')
        
        image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])
        
        images = []
        masks = []
        
        for img_file in image_files:
            # Load image
            img_path = os.path.join(images_dir, img_file)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, self.input_size)
            img = img.astype(np.float32) / 255.0
            images.append(img)
            
            # Load mask
            mask_file = img_file  # Assuming same filename
            mask_path = os.path.join(masks_dir, mask_file)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, self.input_size, interpolation=cv2.INTER_NEAREST)
            masks.append(mask)
        
        return np.array(images), np.array(masks)
    
    def create_data_generator(self, images, masks, augment=True):
        """Create data generator with augmentation"""
        if augment:
            datagen = ImageDataGenerator(
                horizontal_flip=${this.config.dataAugmentation.horizontalFlip},
                vertical_flip=${this.config.dataAugmentation.verticalFlip},
                rotation_range=${this.config.dataAugmentation.rotationRange},
                zoom_range=${this.config.dataAugmentation.zoomRange},
                brightness_range=${this.config.dataAugmentation.brightnessRange},
                contrast_range=${this.config.dataAugmentation.contrastRange},
                fill_mode='nearest'
            )
        else:
            datagen = ImageDataGenerator()
        
        # Create generator
        def generator():
            while True:
                for i in range(0, len(images), self.batch_size):
                    batch_images = images[i:i+self.batch_size]
                    batch_masks = masks[i:i+self.batch_size]
                    
                    # Apply augmentation
                    aug_images = []
                    aug_masks = []
                    
                    for img, mask in zip(batch_images, batch_masks):
                        # Reshape for augmentation
                        img_reshaped = img.reshape((1,) + img.shape)
                        mask_reshaped = mask.reshape((1,) + mask.shape + (1,))
                        
                        # Apply same transformation to image and mask
                        seed = np.random.randint(1000000)
                        aug_img = datagen.flow(img_reshaped, batch_size=1, seed=seed).next()[0]
                        aug_mask = datagen.flow(mask_reshaped, batch_size=1, seed=seed).next()[0]
                        
                        aug_images.append(aug_img)
                        aug_masks.append(aug_mask.squeeze())
                    
                    yield np.array(aug_images), np.array(aug_masks)
        
        return generator()

class UNetModel:
    """UNet architecture for semantic segmentation"""
    
    def __init__(self, input_size, num_classes):
        self.input_size = input_size
        self.num_classes = num_classes
    
    def conv_block(self, inputs, filters, kernel_size=3, padding='same'):
        """Convolutional block with batch normalization and ReLU"""
        x = layers.Conv2D(filters, kernel_size, padding=padding)(inputs)
        x = layers.BatchNormalization()(x)
        x = layers.Activation('relu')(x)
        x = layers.Conv2D(filters, kernel_size, padding=padding)(x)
        x = layers.BatchNormalization()(x)
        x = layers.Activation('relu')(x)
        return x
    
    def build_model(self):
        """Build UNet model"""
        inputs = layers.Input(shape=(*self.input_size, 3))
        
        # Encoder
        c1 = self.conv_block(inputs, 64)
        p1 = layers.MaxPooling2D((2, 2))(c1)
        
        c2 = self.conv_block(p1, 128)
        p2 = layers.MaxPooling2D((2, 2))(c2)
        
        c3 = self.conv_block(p2, 256)
        p3 = layers.MaxPooling2D((2, 2))(c3)
        
        c4 = self.conv_block(p3, 512)
        p4 = layers.MaxPooling2D((2, 2))(c4)
        
        # Bottleneck
        c5 = self.conv_block(p4, 1024)
        
        # Decoder
        u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
        u6 = layers.concatenate([u6, c4])
        c6 = self.conv_block(u6, 512)
        
        u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
        u7 = layers.concatenate([u7, c3])
        c7 = self.conv_block(u7, 256)
        
        u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
        u8 = layers.concatenate([u8, c2])
        c8 = self.conv_block(u8, 128)
        
        u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
        u9 = layers.concatenate([u9, c1])
        c9 = self.conv_block(u9, 64)
        
        # Output layer
        outputs = layers.Conv2D(self.num_classes, (1, 1), activation='softmax')(c9)
        
        model = keras.Model(inputs, outputs)
        return model

def dice_loss(y_true, y_pred, smooth=1e-6):
    """Dice loss for segmentation"""
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def dice_coefficient(y_true, y_pred, smooth=1e-6):
    """Dice coefficient metric"""
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def train_model(dataset_dir, output_dir, config):
    """Main training function"""
    print("Starting candlestick segmentation model training...")
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Initialize dataset generator
    dataset_gen = CandlestickDatasetGenerator(
        dataset_dir, 
        batch_size=config['batchSize'],
        input_size=(config['inputSize']['height'], config['inputSize']['width'])
    )
    
    # Load datasets
    print("Loading training data...")
    train_images, train_masks = dataset_gen.load_dataset('train')
    val_images, val_masks = dataset_gen.load_dataset('val')
    
    print(f"Training samples: {len(train_images)}")
    print(f"Validation samples: {len(val_images)}")
    
    # Convert masks to categorical
    num_classes = len(DATASET_CONFIG['augmentationParams'])
    train_masks_cat = tf.keras.utils.to_categorical(train_masks, num_classes)
    val_masks_cat = tf.keras.utils.to_categorical(val_masks, num_classes)
    
    # Build model
    print("Building model...")
    model_builder = UNetModel(
        input_size=(config['inputSize']['height'], config['inputSize']['width']),
        num_classes=num_classes
    )
    model = model_builder.build_model()
    
    # Compile model
    optimizer_map = {
        'adam': Adam(learning_rate=config['learningRate']),
        'sgd': SGD(learning_rate=config['learningRate']),
        'rmsprop': RMSprop(learning_rate=config['learningRate'])
    }
    
    loss_map = {
        'categorical_crossentropy': CategoricalCrossentropy(),
        'sparse_categorical_crossentropy': SparseCategoricalCrossentropy(),
        'dice_loss': dice_loss
    }
    
    model.compile(
        optimizer=optimizer_map[config['optimizer']],
        loss=loss_map[config['lossFunction']],
        metrics=['accuracy', dice_coefficient]
    )
    
    # Print model summary
    model.summary()
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor=config['earlyStopping']['monitor'],
            patience=config['earlyStopping']['patience'],
            restore_best_weights=True
        ),
        ModelCheckpoint(
            filepath=os.path.join(output_dir, 'best_model.h5'),
            monitor='val_loss',
            save_best_only=True,
            save_weights_only=False
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7
        )
    ]
    
    # Create data generators
    train_gen = dataset_gen.create_data_generator(train_images, train_masks, augment=True)
    val_gen = dataset_gen.create_data_generator(val_images, val_masks, augment=False)
    
    # Calculate steps per epoch
    steps_per_epoch = len(train_images) // config['batchSize']
    validation_steps = len(val_images) // config['batchSize']
    
    # Train model
    print("Starting training...")
    start_time = tf.timestamp()
    
    history = model.fit(
        train_gen,
        steps_per_epoch=steps_per_epoch,
        epochs=config['epochs'],
        validation_data=val_gen,
        validation_steps=validation_steps,
        callbacks=callbacks,
        verbose=1
    )
    
    training_time = tf.timestamp() - start_time
    
    # Save final model
    model.save(os.path.join(output_dir, 'final_model.h5'))
    
    # Save training history
    history_dict = {
        'loss': history.history['loss'],
        'accuracy': history.history['accuracy'],
        'val_loss': history.history['val_loss'],
        'val_accuracy': history.history['val_accuracy'],
        'dice_coefficient': history.history['dice_coefficient'],
        'val_dice_coefficient': history.history['val_dice_coefficient']
    }
    
    with open(os.path.join(output_dir, 'training_history.json'), 'w') as f:
        json.dump(history_dict, f, indent=2)
    
    # Plot training history
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'training_history.png'))
    plt.close()
    
    # Print results
    print(f"\\nTraining completed in {training_time:.2f} seconds")
    print(f"Final training accuracy: {history.history['accuracy'][-1]:.4f}")
    print(f"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}")
    print(f"Final training loss: {history.history['loss'][-1]:.4f}")
    print(f"Final validation loss: {history.history['val_loss'][-1]:.4f}")
    
    return {
        'model_path': os.path.join(output_dir, 'best_model.h5'),
        'training_history': history_dict,
        'training_time': float(training_time),
        'epochs_trained': len(history.history['loss'])
    }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train candlestick segmentation model')
    parser.add_argument('--dataset-dir', required=True, help='Path to dataset directory')
    parser.add_argument('--output-dir', required=True, help='Path to output directory')
    parser.add_argument('--config', help='Path to custom config file')
    
    args = parser.parse_args()
    
    # Load custom config if provided
    if args.config:
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
        CONFIG.update(custom_config)
    
    # Train model
    results = train_model(args.dataset_dir, args.output_dir, CONFIG)
    
    # Save results
    with open(os.path.join(args.output_dir, 'training_results.json'), 'w') as f:
        json.dump(results, f, indent=2)
    
    print("Training completed successfully!")
`;

    return script;
  }

  /**
   * Saves training script to file
   */
  async saveTrainingScript(outputPath: string): Promise<void> {
    const script = await this.generateTrainingScript();
    await fs.writeFile(outputPath, script);
    
    // Make script executable
    await fs.chmod(outputPath, '755');
  }

  /**
   * Generates requirements.txt for Python dependencies
   */
  async generateRequirementsFile(outputPath: string): Promise<void> {
    const requirements = `tensorflow>=2.12.0
keras>=2.12.0
numpy>=1.21.0
opencv-python>=4.5.0
Pillow>=8.0.0
matplotlib>=3.3.0
scikit-learn>=1.0.0
argparse
pathlib
`;

    await fs.writeFile(outputPath, requirements);
  }

  /**
   * Generates training configuration file
   */
  async generateTrainingConfig(outputPath: string): Promise<void> {
    const config = {
      ...this.config,
      datasetConfig: this.datasetConfig,
      generatedAt: new Date().toISOString(),
    };

    await fs.writeFile(outputPath, JSON.stringify(config, null, 2));
  }

  /**
   * Generates complete training package
   */
  async generateTrainingPackage(outputDir: string): Promise<void> {
    console.log('Generating training package...');
    
    // Create output directory
    await fs.mkdir(outputDir, { recursive: true });
    
    // Generate files
    await this.saveTrainingScript(join(outputDir, 'train_model.py'));
    await this.generateRequirementsFile(join(outputDir, 'requirements.txt'));
    await this.generateTrainingConfig(join(outputDir, 'training_config.json'));
    
    // Generate README
    const readme = `# Candlestick Chart Segmentation Model Training

This package contains everything needed to train a segmentation model for candlestick chart analysis.

## Setup

1. Install Python dependencies:
\`\`\`bash
pip install -r requirements.txt
\`\`\`

2. Prepare your dataset using the TypeScript dataset generator

3. Run training:
\`\`\`bash
python train_model.py --dataset-dir /path/to/dataset --output-dir /path/to/output
\`\`\`

## Configuration

Edit \`training_config.json\` to customize training parameters.

## Output

The training will produce:
- \`best_model.h5\`: Best model weights
- \`final_model.h5\`: Final model after all epochs
- \`training_history.json\`: Training metrics
- \`training_history.png\`: Training plots
- \`training_results.json\`: Training summary

## Model Architecture

The model uses a UNet architecture optimized for semantic segmentation of candlestick charts with the following classes:
- Background
- Candle Body (Up)
- Candle Body (Down)
- Candle Wick
- Grid Lines
- Axis Labels
- Chart Area
`;

    await fs.writeFile(join(outputDir, 'README.md'), readme);
    
    console.log(`Training package generated in: ${outputDir}`);
  }
}
